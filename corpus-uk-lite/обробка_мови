https://en.wikipedia.org/wiki/Natural_language_processing

Обробка природної мови (NLP) — це підгалузь лінгвістики, інформатики, інформаційної інженерії та штучного інтелекту, що займається взаємодією між комп’ютерами та людськими (природними) мовами, зокрема тим, як програмувати комп’ютери для обробки та аналізу великих обсягів даних природної мови. .
Проблеми в обробці природної мови часто пов’язані з розпізнаванням мови, розумінням природної мови та створенням природної мови.


== Історія ==
Історія обробки природної мови (NLP) загалом почалася в 1950-х роках, хоча можна знайти роботи з більш ранніх періодів.
У 1950 році Алан Тюрінг опублікував статтю під назвою «Обчислювальна техніка та інтелект», в якій запропоновано те, що зараз називається тестом Тюрінга, як критерій інтелекту.
Джорджтаунський експеримент 1954 року передбачав повністю автоматичний переклад понад шістдесяти російських речень англійською мовою. Автори стверджували, що через три-п'ять років проблема машинного перекладу буде вирішена. Однак реальний прогрес був набагато повільнішим, і після звіту ALPAC у 1966 році, який виявив, що десятирічні дослідження не виправдали очікувань, фінансування машинного перекладу було різко скорочено. До кінця 1980-х років, коли були розроблені перші статистичні системи машинного перекладу, не проводилося подальших досліджень машинного перекладу.
Серед деяких особливо успішних систем обробки природної мови, розроблених у 1960-х роках, були SHRDLU, система природної мови, що працює в обмежених «блокових світах» з обмеженим словниковим запасом, і ELIZA, симуляція роджеріанського психотерапевта, написана Джозефом Вейзенбаумом між 1964 і 1966 роками. не маючи інформації про людські думки чи емоції, ЕЛІЗА іноді забезпечувала вражаюче людську взаємодію. Коли «пацієнт» перевищує дуже невелику базу знань, ELIZA може надати загальну відповідь, наприклад, відповівши на «У мене болить голова» словами «Чому ти кажеш, що у тебе болить голова?».
Протягом 1970-х років багато програмістів почали писати «концептуальні онтології», які структурували інформацію реального світу в дані, зрозумілі комп’ютеру. Прикладами є MARGIE (Schank, 1975), SAM (Cullingford, 1978), PAM (Wilensky, 1978), TaleSpin (Meehan, 1976), QUALM (Lehnert, 1977), Politics (Carbonell, 1979) і Plot Units (Lehnert 1981). ). За цей час було створено багато chatterbots, зокрема PARRY, Racter і Jabberwacky.
До 1980-х років більшість систем обробки природної мови базувалися на складних наборах рукописних правил. Однак, починаючи з кінця 1980-х років, відбулася революція в обробці природної мови з впровадженням алгоритмів машинного навчання для обробки мови. Це було пов’язано як із постійним зростанням обчислювальної потужності (див. закон Мура), так і з поступовим зменшенням домінування теорій Хомського в лінгвістиці (наприклад, трансформаційної граматики), чиї теоретичні основи перешкоджали корпусній лінгвістиці, яка лежить в основі підходу машинного навчання до обробки мови. Деякі з найдавніших алгоритмів машинного навчання, наприклад дерева рішень, створювали системи жорстких правил «якщо-тоді», подібних до існуючих рукописних правил. Однак позначення частин мови запровадило використання прихованих моделей Маркова для обробки природної мови, і все більше дослідження зосереджувалися на статистичних моделях, які приймають м’які ймовірнісні рішення на основі додавання реальних ваг до ознак, що утворюють вхідні дані. даних. Прикладами таких статистичних моделей є мовні моделі кеш-пам’яті, на які зараз спираються багато систем розпізнавання мовлення. Такі моделі, як правило, є більш надійними, коли їм надаються незнайомі вхідні дані, особливо вхідні дані, які містять помилки (як це дуже часто буває для даних реального світу), і дають більш надійні результати, якщо інтегровані у більшу систему, що складається з кількох підзадач.
Багато помітних перших успіхів відбулися в галузі машинного перекладу, особливо завдяки роботі в IBM Research, де послідовно розроблялися більш складні статистичні моделі. Ці системи мали змогу використовувати переваги існуючих багатомовних текстових корпусів, створених парламентом Канади та Європейського Союзу в результаті законів, які вимагають перекладу всіх державних процедур усіма офіційними мовами відповідних державних систем. Однак більшість інших систем залежали від корпусів, спеціально розроблених для завдань, які реалізовували ці системи, що було (і часто залишається) головним обмеженням успіху цих систем. У результаті було проведено багато досліджень щодо методів більш ефективного навчання на основі обмеженої кількості даних.
Останні дослідження дедалі більше зосереджуються на алгоритмах неконтрольованого та напівконтрольованого навчання. Такі алгоритми можуть вивчати дані, які не були анотовані вручну бажаними відповідями або використовуючи комбінацію анотованих і не анотованих даних. Загалом, це завдання є набагато складнішим, ніж контрольоване навчання, і зазвичай дає менш точні результати для певної кількості вхідних даних. Однак існує величезна кількість неанотованих даних (зокрема, весь вміст Всесвітньої павутини), які часто можуть компенсувати гірші результати, якщо алгоритм, що використовується, має достатньо низьку часову складність для бути практичним.
У 2010-х роках навчання репрезентації та методи машинного навчання у стилі глибокої нейронної мережі набули широкого поширення в обробці природної мови, частково завдяки шквалу результатів, які показують, що такі методи можуть досягти найсучасніших результатів у багатьох завданнях природної мови, наприклад, у моделюванні мови, аналізі та багатьох інших. Популярні методи включають використання вбудовування слів для фіксації семантичних властивостей слів і збільшення наскрізного вивчення завдання вищого рівня (наприклад, відповіді на запитання) замість покладання на конвеєр окремих проміжних завдань (наприклад, тегування частин мови та розбір залежностей). У деяких областях цей зсув спричинив суттєві зміни в тому, як розроблені системи НЛП, так що підходи на основі глибоких нейронних мереж можна розглядати як нову парадигму, відмінну від статистичної обробки природної мови. Наприклад, термін нейронний машинний переклад (NMT) підкреслює той факт, що підходи до машинного перекладу, засновані на глибокому навчанні, безпосередньо вивчають перетворення послідовності в послідовність, уникаючи необхідності в проміжних кроках, таких як вирівнювання слів і мовне моделювання, яке використовувалося в статистиці. машинний переклад (SMT).


== На основі правил проти статистичної НЛП ==
У перші дні багато систем обробки мови проектувалися шляхом ручного кодування набору правил: наприклад, шляхом написання граматик або розробки евристичних правил для коріння.
З часу так званої «статистичної революції» наприкінці 1980-х та середини 1990-х років багато досліджень обробки природної мови значною мірою покладалися на машинне навчання. Натомість парадигма машинного навчання передбачає використання статистичних висновків для автоматичного вивчення таких правил за допомогою аналізу великих корпусів (форма множини корпусу, це набір документів, можливо, з людськими або комп’ютерними анотаціями) типових прикладів із реального світу.
Багато різних класів алгоритмів машинного навчання були застосовані до завдань обробки природної мови. Ці алгоритми приймають як вхідні дані великий набір «функцій», які генеруються з вхідних даних. Деякі з найдавніших алгоритмів, таких як дерева рішень, створювали системи жорстких правил «якщо-тоді», подібних до систем рукописних правил, які тоді були поширеними. Однак дослідження дедалі більше зосереджуються на статистичних моделях, які приймають м’які імовірнісні рішення на основі додавання реальних вагових коефіцієнтів до кожної вхідної характеристики. Такі моделі мають ту перевагу, що вони можуть виражати відносну достовірність багатьох різних можливих відповідей, а не лише одну, даючи більш надійні результати, коли таку модель включено як компонент більшої системи.
Системи, засновані на алгоритмах машинного навчання, мають багато переваг перед створеними вручну правилами:

Процедури навчання, які використовуються під час машинного навчання, автоматично фокусуються на найпоширеніших випадках, тоді як під час написання правил від руки часто зовсім неочевидно, куди слід спрямовувати зусилля.
Процедури автоматичного навчання можуть використовувати алгоритми статистичного висновку для створення моделей, стійких до незнайомих вхідних даних (наприклад, що містять слова чи структури, які раніше не зустрічалися) і до помилкових вхідних даних (наприклад, зі словами з помилками або випадково пропущеними словами). Загалом, витончена обробка такого введення за допомогою рукописних правил або, загалом, створення систем рукописних правил, які приймають м’які рішення, є надзвичайно складним, схильним до помилок і займає багато часу.
Системи, засновані на автоматичному навчанні правил, можна зробити більш точними, просто надаючи більше вхідних даних. Однак системи, засновані на рукописних правилах, можна зробити точнішими лише шляхом збільшення складності правил, що є набагато складнішим завданням. Зокрема, існує межа складності систем, заснованих на створених вручну правилах, за якими системи стають усе більш некерованими. Однак створення більшої кількості даних для введення в системи машинного навчання просто вимагає відповідного збільшення кількості відпрацьованих людино-годин, як правило, без істотного збільшення складності процесу анотації.


== Основні оцінки та завдання ==
Нижче наведено список деяких найбільш часто досліджуваних завдань обробки природної мови. Деякі з цих завдань мають безпосереднє застосування в реальному світі, тоді як інші частіше служать підзадачами, які використовуються для допомоги у вирішенні більших завдань.
Хоча завдання обробки природної мови тісно переплетені, їх часто поділяють на категорії для зручності. Приблизний поділ наведено нижче.


=== Синтаксис ===
Граматична індукція - Створіть формальну граматику, яка описує синтаксис мови.
Лематизація - Завдання видалення лише флективних закінчень і повернення базової словникової форми слова, яка також відома як лема.
Морфологічна сегментація - Розділіть слова на окремі морфеми та визначте клас морфем. Складність цього завдання значною мірою залежить від складності морфології (тобто структури слів) мови, що розглядається. Англійська мова має досить просту морфологію, особливо флексійну, і тому часто можна повністю ігнорувати це завдання та просто моделювати всі можливі форми слова (наприклад, «відкрити, відкривається, відкрито, відкривається») як окремі слова. Однак у таких мовах, як турецька чи мейтейська, індійська мова з високим ступенем аглютинації, такий підхід неможливий, оскільки кожна стаття словника містить тисячі можливих словоформ.
Позначення частини мови - За поданим реченням визначте частину мови (ЧС) для кожного слова. Багато слів, особливо загальновживані, можуть виконувати функції кількох частин мови. Наприклад, «книга» може бути іменником («книга на столі») або дієсловом («забронювати рейс»); «set» може бути іменником, дієсловом або прикметником; і "out" може бути будь-якою з принаймні п'яти різних частин мови. Деякі мови мають більше такої двозначності, ніж інші. Мови з невеликою флективною морфологією, такі як англійська, особливо схильні до такої неоднозначності. Китайська мова схильна до такої двозначності, оскільки це тональна мова під час вербалізації. Така флексія нелегко передається за допомогою сутностей, які використовуються в орфографії для передачі наміченого значення.
Розбір - Визначте дерево синтаксичного розбору (граматичний розбір) даного речення. Граматика природних мов є неоднозначною, і типові речення мають кілька можливих аналізів. Можливо, дивно, але для типового речення можуть існувати тисячі потенційних синтаксичних аналізів (більшість з яких здадуться людині абсолютно безглуздими). Існує два основних типи синтаксичного аналізу: аналіз залежності та аналіз групи. Синтаксичний аналіз залежностей зосереджується на зв’язках між словами в реченні (позначає такі речі, як первинні об’єкти та предикати), тоді як синтаксичний аналіз складових зосереджується на побудові дерева аналізу за допомогою ймовірнісної безконтекстної граматики (PCFG). Дивіться також: Стохастична граматика.
Порушення речення (також відоме як усунення неоднозначності межі речення) - За певним фрагментом тексту знайдіть межі речень. Межі речень часто позначаються крапками або іншими знаками пунктуації, але ці самі символи можуть служити й для інших цілей (наприклад, для позначення абревіатур).
Витікання - Процес редукції відмінюваних (або іноді похідних) слів до кореневої форми. (наприклад, "близько" буде коренем для "закрито", "закриття", "закрити", "ближче" тощо).
Сегментація слова - Розділіть фрагмент суцільного тексту на окремі слова. Для такої мови, як англійська, це досить тривіально, оскільки слова зазвичай розділяються пробілами. Однак деякі письмові мови, такі як китайська, японська та тайська, не позначають межі слів таким чином, і в цих мовах сегментація тексту є важливим завданням, яке вимагає знання словникового запасу та морфології слів у мові. Іноді цей процес також використовується в таких випадках, як створення сумки слів (BOW) у видобутку даних.
Вилучення термінології - Метою вилучення термінології є автоматичне вилучення відповідних термінів із даного корпусу.


=== Семантика ===
Лексична семантика - Яке обчислювальне значення окремих слів у контексті?
Дистрибутивна семантика - Як ми можемо дізнатися семантичне представлення з даних?
Машинний переклад - Автоматично перекладайте текст з однієї людської мови на іншу. Це одна з найскладніших проблем, яка належить до класу проблем, які в розмовній мові називаються «повними ШІ», тобто вимагають усіх різних типів знань, якими володіє людина (граматика, семантика, факти про реальний світ тощо). .) правильно розв’язати.
Розпізнавання іменованих об'єктів (NER) - Враховуючи потік тексту, визначте, які елементи в тексті відповідають власним назвам, наприклад людям або місцям, і який тип кожної такої назви (наприклад, особа, місцезнаходження, організація). Хоча використання великих літер може допомогти в розпізнаванні іменованих сутностей у таких мовах, як англійська, ця інформація не може допомогти у визначенні типу іменованої сутності, і в будь-якому випадку часто є неточною або недостатньою. Наприклад, перша літера речення також написана з великої літери, а названі сутності часто охоплюють кілька слів, лише деякі з яких написані з великої літери. Крім того, багато інших мов із незахідним письмом (наприклад, китайська чи арабська) взагалі не мають великих літер, і навіть у мовах із великими літерами вони можуть непостійно використовуватися для розрізнення імен. Наприклад, у німецькій мові всі іменники пишуться з великої літери, незалежно від того, чи є вони іменами, а у французькій та іспанській мовах імена, які служать прикметниками, не пишуться з великої літери.
Генерація природної мови - Перетворення інформації з комп’ютерних баз даних або семантичних намірів на зрозумілу людині мову.
Розуміння природної мови - Перетворення фрагментів тексту на більш формальне відображення, такі як логічні структури першого порядку, якими комп’ютерним програмам легше маніпулювати. Розуміння природної мови передбачає ідентифікацію передбачуваної семантики з безлічі можливих семантик, які можуть бути отримані з виразу природної мови, який зазвичай приймає форму організованих нотацій понять природної мови. Впровадження та створення мовної метамоделі та онтології є ефективними, однак емпіричними рішеннями. Для побудови основи формалізації семантики очікується явна формалізація семантики природної мови без плутанини з неявними припущеннями, такими як припущення закритого світу (CWA) проти припущення відкритого світу або суб’єктивне «Так/Ні» проти об’єктивного «Правда»/Неправда. .
Оптичне розпізнавання символів (OCR) - Дано зображення, яке представляє друкований текст, визначте відповідний текст.
Відповідь на запитання - Дано запитання людською мовою, визначте його відповідь. Типові запитання мають конкретну правильну відповідь (наприклад, «Яка столиця Канади?»), але іноді також розглядаються відкриті запитання (наприклад, «У чому сенс життя?»). Останні роботи розглядають навіть більш складні питання.
Розпізнавання текстового втілення - Дано два фрагменти тексту, визначте, чи істинний один тягне за собою інший, тягне за собою заперечення іншого чи дозволяє іншому бути істинним чи хибним.
Вилучення відносин - Враховуючи фрагмент тексту, визначте зв’язки між названими сутностями (наприклад, хто з ким одружений).
Аналіз настроїв (див. також мультимодальний аналіз настроїв) - Отримайте суб’єктивну інформацію зазвичай із набору документів, часто використовуючи онлайн-огляди для визначення «полярності» щодо конкретних об’єктів. Це особливо корисно для визначення тенденцій громадської думки в соціальних мережах, для маркетингу.
Сегментація та розпізнавання теми - Маючи фрагмент тексту, розділіть його на сегменти, кожен з яких присвячений певній темі, і визначте тему сегмента.
Розпізнавання сенсу слова - Багато слів мають більше одного значення; ми маємо вибрати значення, яке має найбільший сенс у контексті. Для цієї проблеми нам зазвичай дається список слів і пов’язаних слів у значеннях, напр. зі словника або онлайн-ресурсу, наприклад WordNet.


=== Дискурс ===
Автоматичне підведення підсумків
Створіть зрозумілий короткий виклад фрагмента тексту. Часто використовується для надання коротких викладів тексту відомого типу, наприклад, наукових робіт, статей у фінансовому розділі газети.
Роздільна здатність кореференції
Враховуючи речення або більшу частину тексту, визначте, які слова («згадки») стосуються тих самих об’єктів («сутностей»). Розв’язання анафори є конкретним прикладом цього завдання, і воно, зокрема, стосується зіставлення займенників з іменниками чи іменами, до яких вони відносяться. Більш загальне завдання розділення кореференції також включає ідентифікацію так званих «сполучних зв’язків», що включають посилаючі вирази. Наприклад, у такому реченні, як «Він увійшов до будинку Джона через вхідні двері», «вхідні двері» є виразом, що посилається, а сполучний зв’язок, який потрібно визначити, полягає в тому, що двері, про які йдеться, є вхідними дверима Джона будинок (а не будь-яка інша споруда, яку також можна згадати).
Дискурсивний аналіз
Ця рубрика включає кілька пов'язаних завдань. Одним із завдань є визначення структури дискурсу зв’язного тексту, тобто характеру дискурсивних зв’язків між реченнями (наприклад, розробка, пояснення, протиставлення). Іншим можливим завданням є розпізнавання та класифікація мовленнєвих дій у фрагменті тексту (наприклад, запитання «так-ні», питання змісту, твердження, твердження тощо).


=== Виступ ===
Розпізнавання мови
За звуковим фрагментом розмови людини або людей визначте текстове зображення промови. Це протилежність перетворенню тексту в мовлення і є однією з надзвичайно складних проблем, які в розмовній мові називають «повним ШІ» (див. вище). У природному мовленні майже немає пауз між послідовними словами, тому сегментація мовлення є необхідною підзавданням розпізнавання мовлення (див. нижче). У більшості розмовних мов звуки, що представляють послідовні літери, змішуються один з одним у процесі, який називається коартикуляцією, тому перетворення аналогового сигналу на дискретні символи може бути дуже складним процесом. Крім того, враховуючи те, що слова однією мовою вимовляються людьми з різним акцентом, програмне забезпечення для розпізнавання мовлення має мати можливість розпізнавати різноманітні вхідні дані як ідентичні один одному з точки зору його текстового еквівалента.
Сегментація мовлення
Дано звуковий кліп людини або людей, які говорять, розділіть його на слова. Підзавдання розпізнавання мовлення та зазвичай групується з ним.
Синтез мовлення
Дано текст, трансформуйте ці одиниці та створіть усне представлення. Синтез мовлення з тексту можна використовувати для допомоги людям із вадами зору.


=== Діалог ===
Перша опублікована робота штучного інтелекту була опублікована в 2018 році, 1 Дорога, яка продається як роман, містить шістдесят мільйонів слів.
